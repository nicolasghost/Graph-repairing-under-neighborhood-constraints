{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdb1ef0b",
   "metadata": {},
   "source": [
    "# Restaurant Graph Pipeline (fz dataset)\n",
    "\n",
    "## Notebook Overview & Requirements\n",
    "\n",
    "This notebook builds the full pipeline for the restaurant (fz) dataset or graph-based constraint/repair experiments :\n",
    "- Clean raw ARFF and extract `area_code`\n",
    "- Construct similarity edges based on `(addr, city)`\n",
    "- Build graphs: constraint graph `S` and instance graph `G`\n",
    "- Produce cleaned ground truth `G_opt` with no violations\n",
    "- Persist artifacts for downstream perturbation/repair experiments\n",
    "- Import to Neo4j and inject label noise.\n",
    "\n",
    "Tips: tune `ADDRESS_DISTANCE_THRESHOLD` to control similarity density; ensure `.env` is set for Neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4157af8",
   "metadata": {},
   "source": [
    "## Setup & Tunable Parameters\n",
    "\n",
    "- `ARFF_PATH`: path to input ARFF (FZ dataset).\n",
    "- `OUTPUT_DIR`: destination for intermediate and cleaned artifacts.\n",
    "- `ADDRESS_DISTANCE_THRESHOLD`: max edit distance for `addr` similarity within the same `city`.\n",
    "- If `networkx` is available, graph stats/cleaning use it; otherwise a lightweight fallback is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b07841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NetworkX available: True\n",
      "ARFF path: datasets\\restaurant\\fz.arff\n",
      "Output dir: datasets\\temp\n"
     ]
    }
   ],
   "source": [
    "# Setup and Parameters\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Edit distance\n",
    "try:\n",
    "    import Levenshtein\n",
    "    def string_distance(a, b):\n",
    "        return Levenshtein.distance(str(a), str(b))\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\"python-Levenshtein is required; install via pyproject or pip.\")\n",
    "\n",
    "# Optional: NetworkX for convenience (graphs + stats)\n",
    "try:\n",
    "    import networkx as nx\n",
    "    NX_AVAILABLE = True\n",
    "except Exception:\n",
    "    NX_AVAILABLE = False\n",
    "\n",
    "# Parameters (tune as needed)\n",
    "ARFF_PATH = Path(\"datasets/restaurant/fz.arff\")\n",
    "OUTPUT_DIR = Path(\"datasets/temp\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ADDRESS_DISTANCE_THRESHOLD = 7  # max edit distance for addr similarity\n",
    "\n",
    "print(\"NetworkX available:\", NX_AVAILABLE)\n",
    "print(\"ARFF path:\", ARFF_PATH)\n",
    "print(\"Output dir:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb792d47",
   "metadata": {},
   "source": [
    "## Load ARFF\n",
    "\n",
    "- Parses the ARFF header to derive column names and reads the `@data` section into a DataFrame.\n",
    "- Assumes a simple ARFF without sparse rows and with quoted strings.\n",
    "- Output: `df` with columns including `name`, `phone`, `addr`, `city`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "840f8a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 864 rows; columns: ['name', 'addr', 'city', 'phone', 'type', 'class']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>addr</th>\n",
       "      <th>city</th>\n",
       "      <th>phone</th>\n",
       "      <th>type</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arnie morton's of chicago</td>\n",
       "      <td>\"435 s. la cienega blv.\"</td>\n",
       "      <td>\"los angeles\"</td>\n",
       "      <td>\"310/246-1501\"</td>\n",
       "      <td>\"american\"</td>\n",
       "      <td>'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arnie morton's of chicago</td>\n",
       "      <td>\"435 s. la cienega blvd.\"</td>\n",
       "      <td>\"los angeles\"</td>\n",
       "      <td>\"310-246-1501\"</td>\n",
       "      <td>\"steakhouses\"</td>\n",
       "      <td>'0'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>art's delicatessen</td>\n",
       "      <td>\"12224 ventura blvd.\"</td>\n",
       "      <td>\"studio city\"</td>\n",
       "      <td>\"818/762-1221\"</td>\n",
       "      <td>\"american\"</td>\n",
       "      <td>'1'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name                        addr            city  \\\n",
       "0  arnie morton's of chicago    \"435 s. la cienega blv.\"   \"los angeles\"   \n",
       "1  arnie morton's of chicago   \"435 s. la cienega blvd.\"   \"los angeles\"   \n",
       "2         art's delicatessen       \"12224 ventura blvd.\"   \"studio city\"   \n",
       "\n",
       "             phone            type class  \n",
       "0   \"310/246-1501\"      \"american\"   '0'  \n",
       "1   \"310-246-1501\"   \"steakhouses\"   '0'  \n",
       "2   \"818/762-1221\"      \"american\"   '1'  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ARFF into DataFrame\n",
    "from io import StringIO\n",
    "\n",
    "def arff_to_dataframe(filepath: Path) -> pd.DataFrame:\n",
    "    data = False\n",
    "    header = \"\"\n",
    "    csv_content = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip('\\n')\n",
    "            if \"@attribute\" in line.lower():\n",
    "                attributes = line.split()\n",
    "                attri_idx = next(i for i, x in enumerate(attributes) if x.lower() == \"@attribute\")\n",
    "                column_name = attributes[attri_idx + 1]\n",
    "                header = header + column_name + \",\"\n",
    "            elif \"@data\" in line.lower():\n",
    "                data = True\n",
    "                header = header.rstrip(',') + '\\n'\n",
    "                csv_content.append(header)\n",
    "            elif data and line.strip():\n",
    "                csv_content.append(line + '\\n')\n",
    "    csv_string = ''.join(csv_content)\n",
    "    df_local = pd.read_csv(StringIO(csv_string), quotechar='\"')\n",
    "    return df_local\n",
    "\n",
    "# Load\n",
    "df = arff_to_dataframe(ARFF_PATH)\n",
    "print(f\"Loaded {len(df)} rows; columns: {list(df.columns)}\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44512333",
   "metadata": {},
   "source": [
    "## Enrich: Area Code\n",
    "\n",
    "- Derives `area_code` from the first three digits of `phone` (after stripping separators).\n",
    "- Validates expected columns: `name`, `phone`, `addr`, `city`.\n",
    "- Output: `df` includes new `area_code` column (may be `None`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9d3350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area code extraction:\n",
      "  total: 864\n",
      "  with area_code: 864\n",
      "  unique area_codes: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>phone</th>\n",
       "      <th>area_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arnie morton's of chicago</td>\n",
       "      <td>\"310/246-1501\"</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arnie morton's of chicago</td>\n",
       "      <td>\"310-246-1501\"</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>art's delicatessen</td>\n",
       "      <td>\"818/762-1221\"</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>art's deli</td>\n",
       "      <td>\"818-762-1221\"</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hotel bel-air</td>\n",
       "      <td>\"310/472-1211\"</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name            phone area_code\n",
       "0  arnie morton's of chicago   \"310/246-1501\"       310\n",
       "1  arnie morton's of chicago   \"310-246-1501\"       310\n",
       "2         art's delicatessen   \"818/762-1221\"       818\n",
       "3                 art's deli   \"818-762-1221\"       818\n",
       "4              hotel bel-air   \"310/472-1211\"       310"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract area code and basic cleaning\n",
    "\n",
    "def extract_area_code(phone):\n",
    "    if pd.isna(phone) or phone is None:\n",
    "        return None\n",
    "    s = str(phone).strip().strip('\"').strip(\"'\")\n",
    "    digits = s.replace('-', '').replace('/', '').replace(' ', '')\n",
    "    if len(digits) >= 3 and digits[:3].isdigit():\n",
    "        return digits[:3]\n",
    "    return None\n",
    "\n",
    "# Ensure expected columns exist\n",
    "expected_cols = {\"name\", \"phone\", \"addr\", \"city\"}\n",
    "missing = expected_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing expected columns: {missing}\")\n",
    "\n",
    "# Compute area_code\n",
    "df[\"area_code\"] = df[\"phone\"].apply(extract_area_code)\n",
    "\n",
    "print(\"Area code extraction:\")\n",
    "print(\"  total:\", len(df))\n",
    "print(\"  with area_code:\", df[\"area_code\"].notna().sum())\n",
    "print(\"  unique area_codes:\", df[\"area_code\"].nunique())\n",
    "\n",
    "df[[\"name\", \"phone\", \"area_code\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5670dc0",
   "metadata": {},
   "source": [
    "## Similarity Edges\n",
    "\n",
    "- Builds undirected similarity edges where:\n",
    "  - Restaurants share the same `city`, and\n",
    "  - Levenshtein distance on `addr` is `< ADDRESS_DISTANCE_THRESHOLD`.\n",
    "- Output: `similarity_edges` as list of `(i, j)` index pairs.\n",
    "- Note: quadratic in N; acceptable for small datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ceed2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building similarity pairs over 864 restaurants...\n",
      "Similarity summary:\n",
      "  total edges: 5307\n",
      "  avg degree: 12.284722222222221\n",
      "Sample edges: [(0, 1), (0, 22), (0, 242), (1, 22), (1, 242), (2, 3), (2, 37), (2, 706), (3, 37), (3, 706)]\n"
     ]
    }
   ],
   "source": [
    "# Build similarity pairs based on (addr, city)\n",
    "\n",
    "similarity_edges = []\n",
    "N = len(df)\n",
    "print(f\"Building similarity pairs over {N} restaurants...\")\n",
    "for i in range(N):\n",
    "    ai = df.iloc[i]\n",
    "    for j in range(i+1, N):\n",
    "        aj = df.iloc[j]\n",
    "        if ai[\"city\"] != aj[\"city\"]:\n",
    "            continue\n",
    "        d = string_distance(ai[\"addr\"], aj[\"addr\"])\n",
    "        if d < ADDRESS_DISTANCE_THRESHOLD:\n",
    "            similarity_edges.append((i, j))\n",
    "\n",
    "print(\"Similarity summary:\")\n",
    "print(\"  total edges:\", len(similarity_edges))\n",
    "if N:\n",
    "    print(\"  avg degree:\", (2*len(similarity_edges))/N)\n",
    "print(\"Sample edges:\", similarity_edges[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402523e",
   "metadata": {},
   "source": [
    "## Persist: Raw Graph Inputs\n",
    "\n",
    "- Writes two files for downstream steps:\n",
    "  - `restaurants_YYYYMMDD-HHMMSS.txt`: tab-separated `id, name, area_code, addr, city`.\n",
    "  - `restaurant_similarities_YYYYMMDD-HHMMSS.txt`: one edge per line as `(i,j)`.\n",
    "- These represent the uncleaned instance graph inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f23b161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      "   datasets\\temp\\restaurants_20260127-155333.txt\n",
      "   datasets\\temp\\restaurant_similarities_20260127-155333.txt\n"
     ]
    }
   ],
   "source": [
    "# Persist cleaned temp outputs (raw graph inputs)\n",
    "\n",
    "ts = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "restaurants_path = OUTPUT_DIR / f\"restaurants_{ts}.txt\"\n",
    "similarities_path = OUTPUT_DIR / f\"restaurant_similarities_{ts}.txt\"\n",
    "\n",
    "# Ensure area_code exists to avoid KeyError if earlier cell wasn't run\n",
    "if \"area_code\" not in df.columns:\n",
    "    def _extract_area_code_local(phone):\n",
    "        if pd.isna(phone) or phone is None:\n",
    "            return None\n",
    "        s = str(phone).strip().strip('\"').strip(\"'\")\n",
    "        digits = s.replace('-', '').replace('/', '').replace(' ', '')\n",
    "        if len(digits) >= 3 and digits[:3].isdigit():\n",
    "            return digits[:3]\n",
    "        return None\n",
    "    df[\"area_code\"] = df[\"phone\"].apply(_extract_area_code_local)\n",
    "\n",
    "with open(restaurants_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"id\\tname\\tarea_code\\taddr\\tcity\\n\")\n",
    "    for idx, row in df.iterrows():\n",
    "        f.write(f\"{idx}\\t{row['name']}\\t{row['area_code']}\\t{row['addr']}\\t{row['city']}\\n\")\n",
    "\n",
    "with open(similarities_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, j in similarity_edges:\n",
    "        f.write(f\"({i},{j})\\n\")\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"  \", restaurants_path)\n",
    "print(\"  \", similarities_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75efc27",
   "metadata": {},
   "source": [
    "## Graphs & Cleaning\n",
    "\n",
    "- Constraint graph `S`: nodes are `area_code` values; only self-loops are allowed (same-area connections).\n",
    "- Instance graph `G`: nodes are restaurants (with `label = area_code`), edges from `similarity_edges`.\n",
    "- Violation: an edge `(u, v)` where `label(u) != label(v)`.\n",
    "- Cleaning: iteratively remove the lower-degree endpoint of the first found violating edge until none remain, producing `G_opt`.\n",
    "- Outputs: pre/post statistics and number of removed nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4593d86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph stats (before cleaning):\n",
      "  |V|=864, |E|=5307\n",
      "Cleaning results:\n",
      "  violations before: 32\n",
      "  violations after: 0\n",
      "  removed nodes: 15\n",
      "  G_opt |V|=849, |E|=5245\n"
     ]
    }
   ],
   "source": [
    "# Build graphs (S, G) and clean to ground truth (G_opt)\n",
    "\n",
    "# Constraint graph S: nodes = area codes; only self-loops allowed\n",
    "labels = sorted(df[\"area_code\"].dropna().unique().tolist())\n",
    "\n",
    "if NX_AVAILABLE:\n",
    "    S = nx.Graph()\n",
    "    S.add_nodes_from(labels)\n",
    "    S.add_edges_from((ac, ac) for ac in labels)\n",
    "else:\n",
    "    S = {ac: {ac} for ac in labels}  # adjacency-by-label for checks\n",
    "\n",
    "# Instance graph G: nodes = restaurant indices, label = area_code, edges from similarity pairs\n",
    "if NX_AVAILABLE:\n",
    "    G = nx.Graph()\n",
    "    for idx, row in df.iterrows():\n",
    "        G.add_node(int(idx))\n",
    "        G.nodes[int(idx)][\"label\"] = row[\"area_code\"]\n",
    "        G.nodes[int(idx)][\"name\"] = row[\"name\"]\n",
    "        G.nodes[int(idx)][\"addr\"] = row[\"addr\"]\n",
    "        G.nodes[int(idx)][\"city\"] = row[\"city\"]\n",
    "    for u, v in similarity_edges:\n",
    "        if u != v:\n",
    "            G.add_edge(int(u), int(v))\n",
    "else:\n",
    "    # Lightweight structure without networkx\n",
    "    G_nodes = {int(idx): {\n",
    "        \"label\": row[\"area_code\"],\n",
    "        \"name\": row[\"name\"],\n",
    "        \"addr\": row[\"addr\"],\n",
    "        \"city\": row[\"city\"],\n",
    "    } for idx, row in df.iterrows()}\n",
    "    G_edges = {(min(int(u), int(v)), max(int(u), int(v))) for (u, v) in similarity_edges if u != v}\n",
    "\n",
    "# Violation check: neighbors must share same area_code\n",
    "\n",
    "def has_edge_in_S(lu, lv):\n",
    "    if NX_AVAILABLE:\n",
    "        return S.has_edge(lu, lv)\n",
    "    return lv in S.get(lu, set())\n",
    "\n",
    "# Helpers to get the FIRST violating edge with respect to the CURRENT graph state\n",
    "if NX_AVAILABLE:\n",
    "    def first_violation(Gx):\n",
    "        for (u, v) in Gx.edges():\n",
    "            lu = Gx.nodes[u].get(\"label\")\n",
    "            lv = Gx.nodes[v].get(\"label\")\n",
    "            if not has_edge_in_S(lu, lv):\n",
    "                return (u, v)\n",
    "        return None\n",
    "\n",
    "    def count_violations(Gx):\n",
    "        c = 0\n",
    "        for (u, v) in Gx.edges():\n",
    "            lu = Gx.nodes[u].get(\"label\")\n",
    "            lv = Gx.nodes[v].get(\"label\")\n",
    "            if not has_edge_in_S(lu, lv):\n",
    "                c += 1\n",
    "        return c\n",
    "else:\n",
    "    def first_violation(_unused):\n",
    "        for (u, v) in G_edges:\n",
    "            lu = G_nodes[u][\"label\"]\n",
    "            lv = G_nodes[v][\"label\"]\n",
    "            if not has_edge_in_S(lu, lv):\n",
    "                return (u, v)\n",
    "        return None\n",
    "\n",
    "    def count_violations_non_nx():\n",
    "        c = 0\n",
    "        for (u, v) in G_edges:\n",
    "            lu = G_nodes[u][\"label\"]\n",
    "            lv = G_nodes[v][\"label\"]\n",
    "            if not has_edge_in_S(lu, lv):\n",
    "                c += 1\n",
    "        return c\n",
    "\n",
    "# Cleaning: iteratively remove the lower-degree endpoint of first violation until none remain\n",
    "removed = set()\n",
    "if NX_AVAILABLE:\n",
    "    G_opt = G.copy()\n",
    "    viol_before = count_violations(G_opt)\n",
    "    while True:\n",
    "        pair = first_violation(G_opt)\n",
    "        if not pair:\n",
    "            break\n",
    "        u, v = pair\n",
    "        # Guard in case of transient references\n",
    "        if u not in G_opt or v not in G_opt:\n",
    "            continue\n",
    "        drop = u if G_opt.degree[u] <= G_opt.degree[v] else v\n",
    "        removed.add(drop)\n",
    "        G_opt.remove_node(drop)\n",
    "    viol_after = count_violations(G_opt)\n",
    "else:\n",
    "    # Non-NX cleaning\n",
    "    viol_before = count_violations_non_nx()\n",
    "    remaining_nodes = set(G_nodes.keys())\n",
    "    while True:\n",
    "        pair = first_violation(None)\n",
    "        if not pair:\n",
    "            break\n",
    "        u, v = pair\n",
    "        deg_u = sum(1 for e in G_edges if u in e)\n",
    "        deg_v = sum(1 for e in G_edges if v in e)\n",
    "        drop = u if deg_u <= deg_v else v\n",
    "        removed.add(drop)\n",
    "        remaining_nodes.discard(drop)\n",
    "        G_edges = {e for e in G_edges if drop not in e}\n",
    "    viol_after = count_violations_non_nx()\n",
    "\n",
    "print(\"Graph stats (before cleaning):\")\n",
    "if NX_AVAILABLE:\n",
    "    print(f\"  |V|={len(G.nodes)}, |E|={len(G.edges)}\")\n",
    "else:\n",
    "    print(f\"  |V|={len(G_nodes)}, |E|={len(G_edges)}\")\n",
    "\n",
    "print(\"Cleaning results:\")\n",
    "print(\"  violations before:\", viol_before)\n",
    "print(\"  violations after:\", viol_after)\n",
    "print(\"  removed nodes:\", len(removed))\n",
    "if NX_AVAILABLE:\n",
    "    print(f\"  G_opt |V|={len(G_opt.nodes)}, |E|={len(G_opt.edges)}\")\n",
    "else:\n",
    "    print(f\"  G_opt |V|={len(remaining_nodes)}, |E|={len(G_edges)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7298d6",
   "metadata": {},
   "source": [
    "## Persist: Cleaned Ground Truth\n",
    "\n",
    "- Writes `restaurants_cleaned_*.txt` and `restaurant_similarities_cleaned_*.txt`, mirroring the raw formats but restricted to `G_opt`.\n",
    "- These files serve as the canonical, violation-free ground truth for experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5125638d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned ground truth:\n",
      "   datasets\\temp\\restaurants_cleaned_20260127-155349.txt\n",
      "   datasets\\temp\\restaurant_similarities_cleaned_20260127-155349.txt\n"
     ]
    }
   ],
   "source": [
    "# Persist cleaned ground truth artifacts\n",
    "ts2 = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "clean_restaurants_path = OUTPUT_DIR / f\"restaurants_cleaned_{ts2}.txt\"\n",
    "clean_similarities_path = OUTPUT_DIR / f\"restaurant_similarities_cleaned_{ts2}.txt\"\n",
    "\n",
    "# Helper to iterate nodes/edges in G_opt independent of NetworkX\n",
    "if NX_AVAILABLE:\n",
    "    nodes_iter = sorted(G_opt.nodes)\n",
    "    edges_iter = sorted((min(u, v), max(u, v)) for (u, v) in G_opt.edges())\n",
    "else:\n",
    "    nodes_iter = sorted(remaining_nodes)\n",
    "    edges_iter = sorted(G_edges)\n",
    "\n",
    "# Map from id to row for writing attributes\n",
    "by_id = {int(idx): row for idx, row in df.iterrows()}\n",
    "\n",
    "with open(clean_restaurants_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"id\\tname\\tarea_code\\taddr\\tcity\\n\")\n",
    "    for rid in nodes_iter:\n",
    "        r = by_id.get(int(rid))\n",
    "        if r is None:\n",
    "            continue\n",
    "        f.write(f\"{rid}\\t{r['name']}\\t{r['area_code']}\\t{r['addr']}\\t{r['city']}\\n\")\n",
    "\n",
    "with open(clean_similarities_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for u, v in edges_iter:\n",
    "        f.write(f\"({u},{v})\\n\")\n",
    "\n",
    "print(\"Saved cleaned ground truth:\")\n",
    "print(\"  \", clean_restaurants_path)\n",
    "print(\"  \", clean_similarities_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3b1f00",
   "metadata": {},
   "source": [
    "# Import into Neo4j\n",
    "\n",
    "- Uses `.env` for: `NEO4J_URI`, `NEO4J_USERNAME`, `NEO4J_PASSWORD`, `NEO4J_CONSTRAINT_DB`, `NEO4J_INSTANCE_DB`.\n",
    "- GT DB: loads `G_opt` (cleaned) and creates `AreaCode` nodes with self-loops via `:ALLOWED`.\n",
    "- Instance DB: starts as a copy of GT (can be noised later).\n",
    "- Validates that violations are zero after import.\n",
    "\n",
    "### Neo4j Import Details\n",
    "\n",
    "- Constraints: unique on `Restaurant(id)` and `AreaCode(code)`.\n",
    "- Restaurants: properties `name`, `addr`, `city`, `area_code`, and `label = area_code`.\n",
    "- Similarity: undirected similarity imported as two directed `:SIMILAR` relationships.\n",
    "- Constraint graph `S`: collected distinct labels â†’ `AreaCode` nodes with self `:ALLOWED` loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bcfdec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j URI: neo4j://127.0.0.1:7687\n",
      "GT_DB: restaurant-constraint\n",
      "INSTANCE_DB: restaurant-instance\n",
      "GT payload: 849 restaurants, 5245 edges\n",
      "Connected to Neo4j.\n",
      "GT violations: 0 (should be 0)\n",
      "INSTANCE violations: 0 (should be 0)\n",
      "Import done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# --- Env ---\n",
    "env_path = pathlib.Path.cwd() / \".env\"\n",
    "load_dotenv(dotenv_path=env_path, override=True)\n",
    "\n",
    "def _strip_quotes(v):\n",
    "    return None if v is None else v.strip().strip('\"').strip(\"'\")\n",
    "\n",
    "URI = _strip_quotes(os.getenv(\"NEO4J_URI\"))\n",
    "USERNAME = _strip_quotes(os.getenv(\"NEO4J_USERNAME\"))\n",
    "PASSWORD = _strip_quotes(os.getenv(\"NEO4J_PASSWORD\"))\n",
    "GT_DB = _strip_quotes(os.getenv(\"NEO4J_CONSTRAINT_DB\")) or \"restaurants-gt\"   # rename in your head: GT\n",
    "INSTANCE_DB = _strip_quotes(os.getenv(\"NEO4J_INSTANCE_DB\")) or \"restaurants-instance\"\n",
    "\n",
    "AUTH = (USERNAME, PASSWORD)\n",
    "print(\"Neo4j URI:\", URI)\n",
    "print(\"GT_DB:\", GT_DB)\n",
    "print(\"INSTANCE_DB:\", INSTANCE_DB)\n",
    "\n",
    "# --- Neo4j helpers ---\n",
    "def clear_database(driver, database):\n",
    "    driver.execute_query(\"MATCH (n) DETACH DELETE n\", database_=database)\n",
    "\n",
    "def setup_database(driver, database):\n",
    "    driver.execute_query(\"\"\"\n",
    "        CREATE CONSTRAINT restaurant_id_unique IF NOT EXISTS\n",
    "        FOR (r:Restaurant) REQUIRE r.id IS UNIQUE\n",
    "    \"\"\", database_=database)\n",
    "\n",
    "    driver.execute_query(\"\"\"\n",
    "        CREATE CONSTRAINT areacode_code_unique IF NOT EXISTS\n",
    "        FOR (a:AreaCode) REQUIRE a.code IS UNIQUE\n",
    "    \"\"\", database_=database)\n",
    "\n",
    "def import_instance(driver, database, restaurants_list, edges_list):\n",
    "    driver.execute_query(\"\"\"\n",
    "        UNWIND $restaurants AS r\n",
    "        MERGE (n:Restaurant {id: r.id})\n",
    "        SET n.name = r.name,\n",
    "            n.addr = r.addr,\n",
    "            n.city = r.city,\n",
    "            n.area_code = r.area_code,\n",
    "            n.label = r.area_code\n",
    "    \"\"\", restaurants=restaurants_list, database_=database)\n",
    "\n",
    "    # undirected SIMILAR as two directed edges\n",
    "    driver.execute_query(\"\"\"\n",
    "        UNWIND $pairs AS p\n",
    "        MATCH (a:Restaurant {id: p[0]})\n",
    "        MATCH (b:Restaurant {id: p[1]})\n",
    "        MERGE (a)-[:SIMILAR]->(b)\n",
    "        MERGE (b)-[:SIMILAR]->(a)\n",
    "    \"\"\", pairs=edges_list, database_=database)\n",
    "\n",
    "def build_S(driver, database):\n",
    "    driver.execute_query(\"\"\"\n",
    "        MATCH (r:Restaurant)\n",
    "        WITH DISTINCT r.label AS code\n",
    "        WHERE code IS NOT NULL\n",
    "        MERGE (:AreaCode {code: code})\n",
    "    \"\"\", database_=database)\n",
    "\n",
    "    driver.execute_query(\"\"\"\n",
    "        MATCH (a:AreaCode)\n",
    "        MERGE (a)-[:ALLOWED]->(a)\n",
    "    \"\"\", database_=database)\n",
    "\n",
    "def count_violations(driver, database):\n",
    "    rec = driver.execute_query(\"\"\"\n",
    "        MATCH (a:Restaurant)-[:SIMILAR]->(b:Restaurant)\n",
    "        WHERE a.label IS NOT NULL AND b.label IS NOT NULL AND a.label <> b.label\n",
    "        RETURN count(*) AS v\n",
    "    \"\"\", database_=database).records[0]\n",
    "    return rec[\"v\"]\n",
    "\n",
    "# --- Load payloads from CLEANED ground-truth files (produced by cleaning notebook) ---\n",
    "def load_clean_restaurants(path):\n",
    "    rows = []\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        next(f)  # header\n",
    "        for line in f:\n",
    "            rid, name, area_code, addr, city = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            rows.append({\n",
    "                \"id\": str(rid),\n",
    "                \"name\": name,\n",
    "                \"area_code\": None if area_code in (\"None\", \"\") else area_code,\n",
    "                \"addr\": addr,\n",
    "                \"city\": city\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "def load_clean_edges(path):\n",
    "    edges = []\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            s = line.strip().lstrip(\"(\").rstrip(\")\")\n",
    "            if not s:\n",
    "                continue\n",
    "            a, b = [x.strip() for x in s.split(\",\")]\n",
    "            edges.append((str(a), str(b)))\n",
    "    return edges\n",
    "\n",
    "gt_restaurants = load_clean_restaurants(clean_restaurants_path)\n",
    "gt_edges = load_clean_edges(clean_similarities_path)\n",
    "print(\"GT payload:\", len(gt_restaurants), \"restaurants,\", len(gt_edges), \"edges\")\n",
    "\n",
    "# --- Run import ---\n",
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    driver.verify_connectivity()\n",
    "    print(\"Connected to Neo4j.\")\n",
    "\n",
    "    # GT_DB = cleaned G_opt\n",
    "    clear_database(driver, GT_DB)\n",
    "    setup_database(driver, GT_DB)\n",
    "    import_instance(driver, GT_DB, gt_restaurants, gt_edges)\n",
    "    build_S(driver, GT_DB)\n",
    "    print(\"GT violations:\", count_violations(driver, GT_DB), \"(should be 0)\")\n",
    "\n",
    "    # INSTANCE_DB = exact copy of GT for now (noise later)\n",
    "    clear_database(driver, INSTANCE_DB)\n",
    "    setup_database(driver, INSTANCE_DB)\n",
    "    import_instance(driver, INSTANCE_DB, gt_restaurants, gt_edges)\n",
    "    build_S(driver, INSTANCE_DB)\n",
    "    print(\"INSTANCE violations:\", count_violations(driver, INSTANCE_DB), \"(should be 0)\")\n",
    "\n",
    "print(\"Import done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42443bc",
   "metadata": {},
   "source": [
    "## Inject Label Noise (for experiments)\n",
    "\n",
    "- Parameter `FRAUD_NUMBER` (e.g., `10` or `10x`) controls how many restaurants to relabel; parsed as digits only.\n",
    "- Randomly selects `K` restaurants and changes their `label` to a different `AreaCode`.\n",
    "- Annotates modified nodes with `:Fraudulent`, `noise_type = \"label_noise\"`, and `noise_old_label`.\n",
    "- Reports violation count before/after to quantify injected inconsistency.\n",
    "- Use `SEED` for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "359a79f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using K = 10  (from FRAUD_NUMBER = 10x )\n",
      "Using SEED = 42\n",
      "INSTANCE violations BEFORE noise: 0\n",
      "Injected label noise into 10 restaurants.\n",
      "INSTANCE violations AFTER noise: 136\n",
      "Sample updates: [{'id': '668', 'old_label': '213', 'new_label': '818'}, {'id': '123', 'old_label': '212', 'new_label': '770'}, {'id': '34', 'old_label': '213', 'new_label': '212'}, {'id': '773', 'old_label': '702', 'new_label': '805'}, {'id': '295', 'old_label': '212', 'new_label': '702'}, {'id': '264', 'old_label': '310', 'new_label': '100'}, {'id': '238', 'old_label': '818', 'new_label': '100'}, {'id': '151', 'old_label': '404', 'new_label': '212'}, {'id': '768', 'old_label': '702', 'new_label': '310'}, {'id': '113', 'old_label': '718', 'new_label': '310'}]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# ---- Parameters ----\n",
    "# Read FRAUD_NUMBER safely (handles \"10x\" -> 10)\n",
    "raw_k = os.getenv(\"FRAUD_NUMBER\", \"10\")\n",
    "digits = \"\".join(ch for ch in raw_k if ch.isdigit())\n",
    "K = int(digits) if digits else 10\n",
    "\n",
    "SEED = 42  # reproducible noise\n",
    "print(\"Using K =\", K, \" (from FRAUD_NUMBER =\", raw_k, \")\")\n",
    "print(\"Using SEED =\", SEED)\n",
    "\n",
    "def fetch_restaurant_ids(driver, database):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "        MATCH (r:Restaurant)\n",
    "        RETURN r.id AS id\n",
    "        ORDER BY toInteger(r.id)\n",
    "    \"\"\", database_=database)\n",
    "    return [str(r[\"id\"]) for r in res.records]\n",
    "\n",
    "def fetch_area_codes(driver, database):\n",
    "    res = driver.execute_query(\"\"\"\n",
    "        MATCH (a:AreaCode)\n",
    "        RETURN a.code AS code\n",
    "        ORDER BY a.code\n",
    "    \"\"\", database_=database)\n",
    "    return [str(r[\"code\"]) for r in res.records]\n",
    "\n",
    "def inject_label_noise(driver, database, k, seed=42):\n",
    "    rng = random.Random(seed)\n",
    "\n",
    "    ids = fetch_restaurant_ids(driver, database)\n",
    "    codes = fetch_area_codes(driver, database)\n",
    "\n",
    "    if not ids:\n",
    "        raise RuntimeError(\"No Restaurant nodes found.\")\n",
    "    if len(codes) < 2:\n",
    "        raise RuntimeError(\"Need at least 2 distinct AreaCodes to inject label noise.\")\n",
    "\n",
    "    k = min(k, len(ids))\n",
    "    chosen_ids = rng.sample(ids, k)\n",
    "\n",
    "    # Fetch current labels for chosen nodes\n",
    "    res = driver.execute_query(\"\"\"\n",
    "        UNWIND $ids AS id\n",
    "        MATCH (r:Restaurant {id: id})\n",
    "        RETURN r.id AS id, r.label AS old_label\n",
    "    \"\"\", ids=chosen_ids, database_=database)\n",
    "\n",
    "    updates = []\n",
    "    for rec in res.records:\n",
    "        rid = str(rec[\"id\"])\n",
    "        old = rec[\"old_label\"]\n",
    "        # choose a *different* label\n",
    "        new = old\n",
    "        while new == old:\n",
    "            new = rng.choice(codes)\n",
    "        updates.append({\"id\": rid, \"old_label\": old, \"new_label\": new})\n",
    "\n",
    "    # Apply updates\n",
    "    driver.execute_query(\"\"\"\n",
    "        UNWIND $updates AS u\n",
    "        MATCH (r:Restaurant {id: u.id})\n",
    "        SET r.noise_old_label = u.old_label,\n",
    "            r.label = u.new_label,\n",
    "            r.noise_type = \"label_noise\"\n",
    "        SET r:Fraudulent\n",
    "    \"\"\", updates=updates, database_=database)\n",
    "\n",
    "    return updates\n",
    "\n",
    "def count_violations(driver, database):\n",
    "    rec = driver.execute_query(\"\"\"\n",
    "        MATCH (a:Restaurant)-[:SIMILAR]->(b:Restaurant)\n",
    "        WHERE a.label IS NOT NULL AND b.label IS NOT NULL AND a.label <> b.label\n",
    "        RETURN count(*) AS v\n",
    "    \"\"\", database_=database).records[0]\n",
    "    return int(rec[\"v\"])\n",
    "\n",
    "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
    "    driver.verify_connectivity()\n",
    "\n",
    "    # Safety: INSTANCE should start clean\n",
    "    v0 = count_violations(driver, INSTANCE_DB)\n",
    "    print(\"INSTANCE violations BEFORE noise:\", v0)\n",
    "\n",
    "    updates = inject_label_noise(driver, INSTANCE_DB, K, seed=SEED)\n",
    "    print(f\"Injected label noise into {len(updates)} restaurants.\")\n",
    "\n",
    "    v1 = count_violations(driver, INSTANCE_DB)\n",
    "    print(\"INSTANCE violations AFTER noise:\", v1)\n",
    "\n",
    "    # Quick peek: show a few modified nodes\n",
    "    sample = updates[:10]\n",
    "    print(\"Sample updates:\", sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
